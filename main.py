import os
import base64
import requests
from dotenv import load_dotenv
from openai import OpenAI
from taipy.gui import Gui, notify
import taipy.gui.builder as tgb

from PIL import Image
import re
from logger_config import get_logger
from retrieval import load_documents, build_inverted_index, search

logger = get_logger(__name__)
documents = load_documents("data/names.txt")
bm25 = build_inverted_index(documents)


load_dotenv()


def on_init(state):
    state.conv.update_content(state, "")
    state.messages_dict = {}
    state.messages = [
        {
            "role": "assistant",
            "style": "assistant_message",
            "content": "ä½ å¥½! æˆ‘æ˜¯ä¸€ä¸ªåŸºäºQwençš„å¤ä»£æœé¥°æå–åŠ©æ‰‹, è¯·è¾“å…¥éœ€è¦è§£æçš„æ–‡æœ¬æ®µè½: å¦‚å¤´ä¸Šæˆ´ç€é‡‘ä¸å…«å®æ”’ç é«»",
        },
    ]
    state.gpt_messages = []
    new_conv = create_conv(state)
    state.conv.update_content(state, new_conv)


def create_conv(state):
    messages_dict = {}
    with tgb.Page() as conversation:
        for i, message in enumerate(state.messages):
            text = message["content"].replace("<br>", "\n").replace('"', "'")
            messages_dict[f"message_{i}"] = text
            tgb.text(
                "{messages_dict['" + f"message_{i}" + "'] if messages_dict else ''}",
                class_name=f"message_base {message['style']}",
                mode="md",
            )
    state.messages_dict = messages_dict
    return conversation


def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


def format_queries_as_text(queries_results):
    """
    Format a list of queries and their results into a structured plain text string.

    Args:
        queries_results (List[Tuple[str, List[str]]]): List of (query, results) pairs.

    Returns:
        str: Formatted string in plain text style.
    """
    text_output = ""
    text_output += f"è¾“å…¥æ–‡æœ¬æœé¥°è§£æå’Œæ•°æ®åº“ç›¸å…³æœé¥°æ£€ç´¢ç»“æœå¦‚ä¸‹:\n\n"
    for idx, (query, results) in enumerate(queries_results, start=1):
        text_output += f"æœé¥°è§£æç»“æœ {idx}: {query}\n"
        if results:
            for i, result in enumerate(results, start=1):
                text_output += f" æœé¥° {i}: {result}\n"
        else:
            text_output += "æœªåœ¨æ•°æ®åº“ä¸­æ‰¾åˆ°ç±»ä¼¼æœé¥°\n"
        text_output += "\n"  # Extra newline for spacing between queries
    return text_output



def query_gpt4o(state):
    if state.query_image_path != "":
        return "æš‚ä¸æ”¯æŒå›¾ç‰‡è¾“å…¥~"
    else:
        messages = [
                    {'role': 'user', 
                    'content': f"ä½ éœ€è¦æå–è¾“å…¥æ–‡æœ¬ä¸­çš„å…¨éƒ¨è¡£ç€æˆ–é…é¥°ä¿¡æ¯, å¦‚ä»'å¤´ä¸Šæˆ´ç€é‡‘ä¸å…«å®æ”’ç é«»'ä¸­æå–'é‡‘ä¸å…«å®æ”’ç é«»', æ³¨æ„è¾“å‡ºæ—¶ä¸å¯ä»¥ä¿®æ”¹åŸæ–‡å†…å®¹, åº”åŸå°ä¸åŠ¨è¾“å‡º, å¦‚æœæœ‰å¤šä¸ªè¡£ç€æˆ–é…é¥°ä¿¡æ¯, ç”¨ç©ºæ ¼ä½œä¸ºåˆ†å‰²\n{state.query_message}",
                    }
                ]
        response = state.client.chat.completions.create(
            model="qwen-plus", # æ¨¡å‹åˆ—è¡¨ï¼šhttps://help.aliyun.com/zh/model-studio/getting-started/models
            messages=messages,
            )
        response_str = response.choices[0].message.content.replace("\n", "")
        resp_list = re.split(r'\s+', response_str)

    state.gpt_messages.append(messages)
    logger.info(f"Query: {state.query_message}")
    logger.info(f"Response: {response.choices[0].message.content}")

    new_resp_list = []  # list(è§£ææ–‡æœ¬: str, æ£€ç´¢æ–‡æœ¬" List[str])

    for resp in resp_list:
        search_resp = search(resp, bm25, documents, 3)
        # search_respæ˜¯ä¸€ä¸ªtupleï¼Œç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯æ–‡æ¡£å†…å®¹ï¼Œç¬¬äºŒä¸ªå…ƒç´ æ˜¯å¾—åˆ†
        # TODO: æ·»åŠ æ£€ç´¢ç»“æœå¯¹åº”çš„å›¾ç‰‡åœ°å€
        retrieved_docs = [doc[0] for doc in search_resp]
        new_resp_list.append([resp, retrieved_docs])
    # æ ¹æ®æ£€ç´¢ç»“æœæ•´ç†å›å¤æ ¼å¼å¹¶ç”Ÿæˆå›å¤æ¶ˆæ¯
    resp_text = format_queries_as_text(new_resp_list)

    return resp_text


def send_message(state):
    if state.query_image_path == "":
        state.messages.append(
            {
                "role": "user",
                "style": "user_message",
                "content": state.query_message,
            }
        )
    else:
        state.messages.append(
            {
                "role": "user",
                "style": "user_message",
                "content": f"{state.query_message}\n![user_image]({state.query_image_path})",
            }
        )
    state.conv.update_content(state, create_conv(state))
    notify(state, "info", "Sending message...")
    state.messages.append(
        {
            "role": "assistant",
            "style": "assistant_message",
            "content": f"{query_gpt4o(state)}",
        }
    )
    # state.messages.append(
    #     {
    #         "role": "assistant",
    #         "style": "assistant_message",
    #         "content": f"{query_gpt4o(state)}![assistant_image](images/example_0.png)",
    #     }
    # )
    state.conv.update_content(state, create_conv(state))
    state.query_message = ""
    state.query_image_path = ""


def upload_image(state):
    try:
        global index
        image = Image.open(state.query_image_path)
        image.thumbnail((300, 300))
        image.save(f"images/example_{index}.png")
        state.query_image_path = f"images/example_{index}.png"
        index = index + 1
    except:
        notify(
            state,
            "error",
            f"Please make sure your image is under 1MB",
        )


def reset_chat(state):
    state.messages = []
    state.gpt_messages = []
    state.query_message = ""
    state.query_image_path = ""
    state.conv.update_content(state, create_conv(state))
    on_init(state)


if __name__ == "__main__":
    index = 0
    query_image_path = ""
    query_message = ""
    messages = []
    gpt_messages = []
    messages_dict = {}
    client = OpenAI(
        api_key=os.getenv("OPENAI_API_KEY"),
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    )

    with tgb.Page() as page:
        with tgb.layout(columns="300px 1"):
            with tgb.part(class_name="sidebar"):
                tgb.text("## Taipy x GPT-4o", mode="md")
                tgb.button(
                    "New Conversation",
                    class_name="fullwidth plain",
                    id="reset_app_button",
                    on_action=reset_chat,
                )
                tgb.html("br")
                tgb.image(
                    content="{query_image_path}", width="250px", class_name="image_preview"
                )

            with tgb.part(class_name="p1"):
                tgb.part(partial="{conv}", height="600px", class_name="card card_chat")
                with tgb.part("card mt1"):
                    tgb.input(
                        "{query_message}",
                        on_action=send_message,
                        change_delay=-1,
                        label="Write your message:",
                        class_name="fullwidth",
                    )
                    tgb.file_selector(
                        content="{query_image_path}",
                        on_action=upload_image,
                        extensions=".jpg,.jpeg,.png",
                        label="Upload an image",
                    )
                    tgb.text("Max file size: 1MB")
    gui = Gui(page)
    conv = gui.add_partial("")
    gui.run(title="ğŸ¤–Taipy x GPT-4o", dark_mode=False, margin="0px", debug=True, use_reloader=True)
